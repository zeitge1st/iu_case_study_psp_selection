{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6323f327-c470-42a5-aecc-4b8b68b11973",
   "metadata": {},
   "source": [
    "Fallstudie:<br> \n",
    "**Erstellen eines Prognosemodells des Kreditkartenzahlungsverkehr für Online-Einkäufe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fa2c8-c490-46ff-b471-8dfe2efeb277",
   "metadata": {},
   "source": [
    "# Import & Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e1e74e-0d09-436a-8f92-14ee75df9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167a0ecb-5f75-47b8-b2dc-06c157506e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "pd.option_context('mode.use_inf_as_na', True)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid',)\n",
    "color_pal = sns.color_palette(\"muted\")\n",
    "sns.set_palette(color_pal)\n",
    "sns.set_context(\"paper\")\n",
    "%matplotlib inline\n",
    "# plot dimensions\n",
    "plot_width = 12\n",
    "plot_height = 8\n",
    "palette_success ={0: color_pal[1], 1: color_pal[2]}\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, f1_score, recall_score, make_scorer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2542783-5c34-46c7-ab32-960fa8a3b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_model(training_info, model, x_test, y_test, y_pred, y_pred_auc, feature_names):\n",
    "    # Set a tag as detailed description of run\n",
    "    mlflow.set_tag(\"Training Info\", training_info)\n",
    "    \n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(model.get_params())\n",
    "    \n",
    "    # Log the metrics\n",
    "    mlflow.log_metrics({\"AUC\": roc_auc_score(y_test, y_pred_auc), \n",
    "                       \"Precision\": precision_score(y_test, y_pred, zero_division=np.nan), \n",
    "                       \"Recall\": recall_score(y_test, y_pred, zero_division=np.nan), \n",
    "                       \"F1-score\": f1_score(y_test, y_pred, zero_division=np.nan)})\n",
    "    \n",
    "    # built-in FEATURE IMPORTANCE ##############################################\n",
    "    # check options to find out import of features\n",
    "    plot_title = \"No information\"\n",
    "    if (hasattr(model, \"feature_importances_\") == True):\n",
    "        feat_imp = model.feature_importances_\n",
    "        plot_title = \"Feature importances\"\n",
    "    elif (hasattr(model, \"coef_\") == True):\n",
    "        feat_imp = model.coef_[0]\n",
    "        plot_title = \"Coefficients\"\n",
    "    else:\n",
    "        feat_imp = len(feature_names) * [0]\n",
    "        print(\"Has NO feature importances\")\n",
    "    \n",
    "    # Log feature importance as artifacts\n",
    "    df_feat_imp = (pd.DataFrame(list(zip(feature_names, feat_imp)), \n",
    "                             columns=[\"Feature\", \"Importance\"])\n",
    "                .sort_values(\"Importance\", ascending=False)\n",
    "                .set_index(\"Feature\"))\n",
    "    csv_path = \"artifacts/feature_importance.csv\"\n",
    "    df_feat_imp.to_csv(csv_path, index=True)\n",
    "    mlflow.log_artifact(csv_path, \"feature_importance.csv\")\n",
    "    \n",
    "    # Log plot of feature importance\n",
    "    fig, ax = plt.subplots()\n",
    "    df_feat_imp.plot.barh(ax=ax)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.subplots_adjust(left=0.4, right=0.95, top=0.9, bottom=0.1)\n",
    "    mlflow.log_figure(fig, \"feature_importance.png\")\n",
    "\n",
    "    # PERMUTATION FEATURE IMPORTANCE (PFI) #############################################\n",
    "    pfi_result = permutation_importance(estimator=model, X=x_test, y=y_test, scoring=\"roc_auc\", random_state=23, n_repeats=10)\n",
    "    df_pfi = (pd.DataFrame(list(zip(feature_names, pfi_result.importances_mean)), \n",
    "                           columns=[\"Feature\", \"PFI\"])\n",
    "              .sort_values(\"PFI\", ascending=False)\n",
    "              .set_index(\"Feature\"))\n",
    "    csv_path_pfi = \"artifacts/pfi.csv\"\n",
    "    df_pfi.to_csv(csv_path_pfi, index=True)\n",
    "    mlflow.log_artifact(csv_path_pfi, \"pfi.csv\")\n",
    "\n",
    "    # Log plot of PFI\n",
    "    fig, ax = plt.subplots()\n",
    "    df_feat_imp.plot.barh(ax=ax)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.subplots_adjust(left=0.4, right=0.95, top=0.9, bottom=0.1)\n",
    "    mlflow.log_figure(fig, \"feature_importance.png\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Infer the model signature\n",
    "    #signature = infer_signature(x_train, y_train)\n",
    "    # Log the model\n",
    "    \"\"\"model_info = mlflow.sklearn.log_model(sk_model=model, \n",
    "                                          artifact_path=\"baseline_model\", \n",
    "                                          signature=signature, \n",
    "                                          input_example=x_train.head(5))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c4c5e-40b0-4def-bf92-6e67810db034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "rs = 23 # random state\n",
    "\n",
    "# MLflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# date of today as string\n",
    "dt_today = str(dt.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27845bea-2fef-4bc9-868f-89a29663c32b",
   "metadata": {},
   "source": [
    "# Data preparation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276cade-ad1a-46e2-aa75-0eb7dcd3b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx = (pd.read_excel(\"../data/03_interim/df_trx_training.xlsx\", sheet_name=\"df_trx\")\n",
    "          .drop(columns=[\"Unnamed: 0\"])\n",
    "          .rename(columns={\"x_tmsp\":\"meta_tmsp\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590679a-d589-481e-bcc4-64bfee6c6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw x- and y-variables\n",
    "x_ = [x for x in list(df_trx.columns) if re.match(\"^x_\", x)!=None]\n",
    "y_ = [y for y in list(df_trx.columns) if re.match(\"^y_\", y)!=None]\n",
    "meta_ = [m for m in list(df_trx.columns) if m.find(\"meta_\")!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba8f6c0-7cc1-42a1-adb1-d787e66cde75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx[x_].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6adc2-f46e-49e0-8e5c-e706142357fe",
   "metadata": {},
   "source": [
    "Je nach Modell gibt es 2 Features-Sets:<br>\n",
    "\n",
    "Für Modelle, die numerische Features benötigen: \n",
    "- 16 Features\n",
    "- davon 6 numerische Features, die skaliert werden müssen\n",
    "- und 10 Features vom Typ Boolean, die aus dem One Hot Encoding entstanden sind und als Integer encoded werden<br>\n",
    "\n",
    "Für Modelle, bei denen der Typ der Features egal ist:\n",
    "- 11 Features\n",
    "- davon 6 numerische Features\n",
    "- und 5 categorial Features vom Typ Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577b15c-f507-4777-95ff-9412a035ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize features\n",
    "feat_object_native = list(df_trx[x_].select_dtypes(include=\"object\").columns) # original features of type object\n",
    "#feat_object_bool_enc = list(df_trx[x_].select_dtypes(include=\"bool\").columns) # encoded object features as bool\n",
    "feat_num = list(df_trx[x_].select_dtypes(include=\"number\").columns) # numerical features for scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dba4fc-54b8-4f6a-9362-955246c6426d",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16057397-cc6c-4ba5-a29f-ba6a722e10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and stratify\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_trx[x_], df_trx[y_], test_size=0.2, random_state=rs, shuffle=True, stratify=df_trx[y_])\n",
    "y_train= y_train.iloc[:, 0]\n",
    "y_test= y_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592c3cd-195e-477f-a3ac-f09e20ba0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = x_train.shape[0]\n",
    "test_size = x_test.shape[0]\n",
    "print(f\"Trainings data set consists of {train_size} records, while the test data set consists of {test_size} records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a48092-caac-4827-8951-3deba27a6f3e",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1003b-2a87-4888-91fb-0f4b16844fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer for models requiring numerical, scaled input features\n",
    "coltransformer_4numerical = make_column_transformer(\n",
    "    (MinMaxScaler(), make_column_selector(dtype_include=\"number\")), \n",
    "    (OrdinalEncoder(), make_column_selector(dtype_include=\"bool\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480c6ff-fae8-40a2-9d71-154c461845f8",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76340a0-a00d-4b90-b751-5f7d0a13de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model with numerical input\n",
    "coltransformer_4numerical.fit(x_train)\n",
    "x_train_numerical = coltransformer_4numerical.transform(x_train)\n",
    "x_test_numerical = coltransformer_4numerical.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ba462-2a14-464c-90e1-9d9728cbe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model with raw input\n",
    "x_train_raw = x_train[feat_num + feat_object_native]\n",
    "x_test_raw = x_test[feat_num + feat_object_native]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507a335-d408-430e-82ee-251a3eecb53f",
   "metadata": {},
   "source": [
    "# Modeling no. 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0062566-a494-483a-9198-13d6362a7bcc",
   "metadata": {},
   "source": [
    "## Test design\n",
    "Ziele:\n",
    "- erfolgreiche Transaktionen in Abhängigkeit vom PSP (und den anderen Umständen) erkennen\n",
    "- positiv = success\n",
    "- wir müssen dem Kunden einen PSP zuordnen und wollen daher den PSP wählen, der die höchste Erfolgswahrscheinlichkeit hat\n",
    "- keine PSP zu wählen ist keine Option\n",
    "  \n",
    "Vergleich der Modelle:\n",
    "- Wir sind nicht nur an der Klassifikation an sich interessiert, sondern v.a. auch an der Wahrscheinlichkeit für einen Erfolg abhängig von dem PSP. Der Predictor muss keine fixe Vorhersage über Erfolg/Misserfolg treffen, sondern in Abhängigkeit vom PSP die Erfolgswahrscheinlichkeit berechnen (es wird kein Threshold festgelegt).\n",
    "- AUC ist eine Vergleichsmetrik, die unabhängig vom gewählten Threshold ist.\n",
    "\n",
    "Weitere Metriken zur Bewertung der Performance, aber nicht entscheidend:\n",
    "- Precision meiner Vorhersage: keine Falschpositiven, um mehrfache Transaktionsgebühren zu sparen\n",
    "- Recall/TPR/Sensitivity: möglichst viele erfolgreiche Transaktionen vorhersagen, um eine Auswahl an PSPs zu haben, um die Kosten minimieren zu können\n",
    "- F1-Score als harmonisches Mittel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b4dce-5d41-4aeb-ab9b-7002f0fd611b",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "2 Strategien kommen in Frage:\n",
    "- most_frequent: macht wenig Sinn, weil dann kein Erfolg vorhergesagt wird, so dass Precision nicht berechnet werden kann. Recall/Sensitity ist ebenfalls = 0\n",
    "- stratified: It generates predictions by respecting the class distribution of the training data. It is different from the “most frequent” strategy as it instead associates a probability with each data point of being the most frequent class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5b0aa-b910-49aa-8f56-2a72cf20673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and prediction\n",
    "baseline_clf = DummyClassifier(strategy=\"stratified\", random_state=rs)\n",
    "baseline_clf.fit(x_train_raw, y_train)\n",
    "\n",
    "y_pred_baseline = baseline_clf.predict(x_test_raw)\n",
    "y_pred_baseline_prob = baseline_clf.predict_proba(x_test_raw)\n",
    "auc = roc_auc_score(y_test, y_pred_baseline_prob[:, 1], average=\"macro\")\n",
    "prec = precision_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "recall = recall_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "f1 = f1_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "\n",
    "print(f\"Baseline-model\")\n",
    "print(f\"with AUC: {auc:.2f}\")\n",
    "print(f\"with precision: {prec:.2f}\")\n",
    "print(f\"with recall: {recall:.2f}\")\n",
    "print(f\"and F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7fa4d-c415-4de9-a236-96e223866f10",
   "metadata": {},
   "source": [
    "## 1st training of models (w/o class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e553a5d-e323-40a4-a120-501f32f3616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdfb47-16cb-427f-9e1e-9157f3c4d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all models\n",
    "# names\n",
    "first_step_clf_names = [\"Baseline model stratified\", \n",
    "                        \"Logistic Regression\", \n",
    "                        \"Naive Bayes\", \n",
    "                        \"KNN\", \n",
    "                        \"Decision Tree\", \n",
    "                        \"Linear SVM\"  \n",
    "                        \"SVC\", \n",
    "                        \"LDA\", \n",
    "                        \"QDA\",\n",
    "                        \"Random Forest\", \n",
    "                        \"Gradient Boosting\", \n",
    "                        \"Extra Trees\"]\n",
    "\n",
    "# configure random see\n",
    "params_rs = {\"random_state\": rs}\n",
    "\n",
    "# sklearn models\n",
    "first_step_clf = [DummyClassifier(strategy=\"stratified\", **params_rs), \n",
    "                  LogisticRegression(penalty=None, **params_rs), \n",
    "                  CategoricalNB(), \n",
    "                  KNeighborsClassifier(), \n",
    "                  DecisionTreeClassifier(**params_rs),\n",
    "                  LinearSVC(**params_rs)\n",
    "                  SVC(probability=True, **params_rs), \n",
    "                  LinearDiscriminantAnalysis(), \n",
    "                  QuadraticDiscriminantAnalysis(),\n",
    "                  RandomForestClassifier(**params_rs), \n",
    "                  GradientBoostingClassifier(**params_rs), \n",
    "                  ExtraTreesClassifier(**params_rs)]\n",
    "\n",
    "# feature mode for model\n",
    "first_step_feat_mode = [\"raw\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\"]\n",
    "\n",
    "first_step_zip = zip(first_step_clf_names, first_step_clf, first_step_feat_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0902b09-59e7-4290-9ca8-e895a2b04162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_exp = \"PSP_1_w/o_class_weights\"\n",
    "first_info = \"1. Training for comparison of models WITHOUT hyperparameter tuning\"\n",
    "for n, c, fm in first_step_zip:\n",
    "    print(f\"Training and logging of model {n} as classifier {c} with feature mode {fm}\")\n",
    "    if fm == \"raw\":\n",
    "        x_train = x_train_raw\n",
    "        x_test = x_test_raw\n",
    "        feature_names = list(x_train_raw.columns)\n",
    "    else:\n",
    "        x_train = x_train_numerical\n",
    "        x_test = x_test_numerical\n",
    "        feature_names = list(coltransformer_4numerical.get_feature_names_out())\n",
    "        \n",
    "    # Create a new MLflow Experiment\n",
    "    mlflow.set_experiment(first_exp)\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    run_name = dt_today + \"_\" + n\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        training_info = n + \" - \" + first_info\n",
    "        # Training and prediction\n",
    "        model = c\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        f (hasattr(model, \"decision_function\") == True):\n",
    "            y_pred_auc = model.decision_function(x_test)\n",
    "        else:\n",
    "            y_pred_auc = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "        track_model(training_info, model, y_test, y_pred, y_pred_auc, feature_names)\n",
    "\n",
    "        run_id = run.info.run_id\n",
    "    \n",
    "    print(f\"For {n}: Run logged in MLflow with {run_id}.\")\n",
    "    print(\"---------------------- \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836147a-4de5-4497-9449-a21d6eec42c0",
   "metadata": {},
   "source": [
    "## Evaluate & understand 1st model training\n",
    "https://christophm.github.io/interpretable-ml-book/feature-importance.html\n",
    "https://scikit-learn.org/stable/modules/permutation_importance.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa54559-4e63-4ff6-9ede-2bb083ef8a05",
   "metadata": {},
   "source": [
    "# Modeling no. 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d62c6-4836-4356-8a70-b33414184b4f",
   "metadata": {},
   "source": [
    "## Random search for hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c9f08f-dc57-4e60-8f10-bf471d1dedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all models\n",
    "# names\n",
    "hp_clf_names = [\"Logistic Regression\",  \n",
    "                \"KNN\", \n",
    "                \"Decision Tree\", \n",
    "                \"Linear SVM\", \n",
    "                \"SVC\",\n",
    "                \"Random Forest\", \n",
    "                \"Gradient Boosting\", \n",
    "                \"Extra Trees\"]\n",
    "\n",
    "# configure parameters per model\n",
    "hp_baseline = {\"strategy\": [\"most_frequent\", \"stratified\"]}\n",
    "hp_lr = {\"penalty\": [\"l1\", \"l2\", \"elasticnet\", None], \n",
    "         \"C\": np.arange(0.01, 10, 0.1), \n",
    "         \"l1_ratio\": np.arange(0.1, 1.01, 0.1)}\n",
    "hp_nb = {\"alpha\": np.arange(0, 10, 0.1)}\n",
    "hp_knn = {\"n_neighbors\": np.arange(5, 52, 2), \n",
    "          \"weights\": [\"uniform\", \"distance\"], \n",
    "          \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"], \n",
    "          \"p\": np.arange(1, 2.1, 0.1)}\n",
    "hp_dt = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"], \n",
    "         \"splitter\": [\"best\", \"random\"], \n",
    "         \"max_depth\": np.arange(2, 52, 2), \n",
    "         \"min_samples_split\": np.arange(2, 52, 2), \n",
    "         \"min_samples_leaf\": np.arange(1, 32, 2)}\n",
    "hp_lin_svm = {\"penalty\": [\"l1\", \"l2\"], \n",
    "              \"C\": np.arange(0, 10, 0.1)}\n",
    "hp_svc = {\"C\": np.arange(0, 10, 0.1), \n",
    "          \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "          \"degree\":[2, 3, 4, 5], \n",
    "          \"gamma\":[\"scale\", \"auto\"]}\n",
    "hp_rf = {\"n_estimators\": np.arange(10, 300, 20), \"criterion\": [\"gini\", \"entropy\", \"log_loss\"], \n",
    "         \"max_depth\": np.arange(2, 50, 2), \n",
    "         \"min_samples_split\": np.arange(2, 50, 2), \n",
    "         \"min_samples_leaf\": np.arange(1, 30, 2), \n",
    "         \"max_features\": [None, \"sqrt\", \"log2\"]}\n",
    "hp_grad_boost = {\"loss\": [\"log_loss\", \"exponential\"], \n",
    "                 \"learning_rate\":np.arange(0.1, 1.5, 0.1), \n",
    "                 \"subsample\": np.arange(0.3, 0.99, 0.1), \n",
    "                 \"criterion\": [\"friedman_mse\", \"squared_error\"], \n",
    "                 \"min_samples_split\": np.arange(2, 50, 2), \n",
    "                 \"min_samples_leaf\": np.arange(1, 30, 2), \n",
    "                 \"max_depth\": np.arange(2, 50, 2), \n",
    "                 \"max_features\": [None, \"sqrt\", \"log2\"]}\n",
    "hp_extra = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"], \n",
    "            \"max_depth\": np.arange(2, 52, 2), \n",
    "            \"min_samples_split\": np.arange(2, 52, 2), \n",
    "            \"min_samples_leaf\": np.arange(1, 32, 2), \n",
    "            \"max_features\": [None, \"sqrt\", \"log2\"], \n",
    "            \"min_weight_fraction_leaf\": np.arange(0, 0.5, 0.1)}\n",
    "\n",
    "# parameters collected\n",
    "hp_params = [hp_lr, hp_knn, hp_dt, hp_lin_svm, hp_svc, hp_rf, hp_grad_boost, hp_extra]\n",
    "\n",
    "# sklearn models\n",
    "hp_clf = [LogisticRegression(solver=\"saga\", random_state=rs), \n",
    "          KNeighborsClassifier(), \n",
    "          DecisionTreeClassifier(random_state=rs), \n",
    "          LinearSVC(dual=\"auto\", random_state=rs), \n",
    "          SVC(probability=True, random_state=rs),\n",
    "          RandomForestClassifier(random_state=rs), \n",
    "          GradientBoostingClassifier(random_state=rs), \n",
    "          ExtraTreesClassifier(random_state=rs)]\n",
    "\n",
    "# feature mode for model\n",
    "hp_feat_mode = [\"numeric\", \n",
    "                \"numeric\", \n",
    "                \"numeric\", \n",
    "                \"numeric\", \n",
    "                \"numeric\", \n",
    "                \"numeric\", \n",
    "                \"numeric\", \n",
    "                \"numeric\"]\n",
    "\n",
    "hp_zip = zip(hp_clf_names, hp_clf, hp_params, hp_feat_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72235301-af91-4d4d-8fb4-e9cd413aa270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config RandomizedSearchCV\n",
    "scorer_auc = make_scorer(roc_auc_score)\n",
    "scorer_precision = make_scorer(precision_score)\n",
    "scorer_recall = make_scorer(recall_score)\n",
    "scorer_f1 = make_scorer(f1_score)\n",
    "\n",
    "randomized_scoring = {\"auc\": scorer_auc, \n",
    "                        \"precision\": scorer_precision, \n",
    "                        \"recall\": scorer_recall, \n",
    "                        \"F1\": scorer_f1}\n",
    "randomized_iter = 30\n",
    "randomized_cv = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d912b-d251-4fd2-bdfb-b3f1a2065d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"experiment = \"PSP_1_w/o_class_weights\"\n",
    "info = \"Training incl hyperparameter tuning\"\n",
    "\n",
    "for n, c, p, fm in hp_zip:\n",
    "    print(f\"RandomSearchCV and logging of model {n} as classifier {c} with feature mode {fm}\")\n",
    "    if fm == \"raw\":\n",
    "        x_train = x_train_raw\n",
    "        x_test = x_test_raw\n",
    "        feature_names = list(x_train_raw.columns)\n",
    "    else:\n",
    "        x_train = x_train_numerical\n",
    "        x_test = x_test_numerical\n",
    "        feature_names = list(coltransformer_4numerical.get_feature_names_out())\n",
    "        \n",
    "    # Create a new MLflow Experiment\n",
    "    mlflow.set_experiment(experiment)\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    run_name = dt_today + \"_\" + n + \"_BestPredictor\"\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        training_info = n + \" - \" + info\n",
    "\n",
    "        random_search = RandomizedSearchCV(c, \n",
    "                                           param_distributions=p, \n",
    "                                           n_iter=randomized_iter, \n",
    "                                           verbose=2, \n",
    "                                           cv=randomized_cv, \n",
    "                                           scoring=randomized_scoring, \n",
    "                                           refit=\"auc\", \n",
    "                                           random_state=rs, \n",
    "                                           error_score=\"raise\")\n",
    "        # Training and prediction\n",
    "        random_search.fit(x_train, y_train)\n",
    "        model_best = random_search.best_estimator_\n",
    "        y_pred = model_best.predict(x_test)\n",
    "\n",
    "        track_model(training_info, model_best, y_test, y_pred, feature_names)\n",
    "\n",
    "        run_id = run.info.run_id\n",
    "    \n",
    "    print(f\"For {n}: Run logged in MLflow with {run_id}.\")\n",
    "    print(\"---------------------- \\n\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4427e-0800-4cef-8b99-0efe3db6c1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
