{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6323f327-c470-42a5-aecc-4b8b68b11973",
   "metadata": {},
   "source": [
    "Fallstudie:<br> \n",
    "**Erstellen eines Prognosemodells des Kreditkartenzahlungsverkehr für Online-Einkäufe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e1e74e-0d09-436a-8f92-14ee75df9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167a0ecb-5f75-47b8-b2dc-06c157506e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.option_context('mode.use_inf_as_na', True)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid',)\n",
    "color_pal = sns.color_palette(\"muted\")\n",
    "sns.set_palette(color_pal)\n",
    "sns.set_context(\"paper\")\n",
    "%matplotlib inline\n",
    "# plot dimensions\n",
    "plot_width = 12\n",
    "plot_height = 8\n",
    "palette_success ={0: color_pal[1], 1: color_pal[2]}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, f1_score, recall_score\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271c4c5e-40b0-4def-bf92-6e67810db034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "rs = 23 # random state\n",
    "\n",
    "# MLflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# date of today as string\n",
    "dt_today = str(dt.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27845bea-2fef-4bc9-868f-89a29663c32b",
   "metadata": {},
   "source": [
    "# Data preparation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8276cade-ad1a-46e2-aa75-0eb7dcd3b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx = (pd.read_excel(\"../data/03_interim/df_trx_training.xlsx\", sheet_name=\"df_trx\")\n",
    "          .drop(columns=[\"Unnamed: 0\"])\n",
    "          .rename(columns={\"x_tmsp\":\"meta_tmsp\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f590679a-d589-481e-bcc4-64bfee6c6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw x- and y-variables\n",
    "x_ = [x for x in list(df_trx.columns) if re.match(\"^x_\", x)!=None]\n",
    "y_ = [y for y in list(df_trx.columns) if re.match(\"^y_\", y)!=None]\n",
    "meta_ = [m for m in list(df_trx.columns) if m.find(\"meta_\")!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba8f6c0-7cc1-42a1-adb1-d787e66cde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37612 entries, 0 to 37611\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   x_country                  37612 non-null  object \n",
      " 1   x_amount                   37612 non-null  int64  \n",
      " 2   x_psp                      37612 non-null  object \n",
      " 3   x_3d_secured               37612 non-null  int64  \n",
      " 4   x_card                     37612 non-null  object \n",
      " 5   x_tmsp_wd_str              37612 non-null  object \n",
      " 6   x_tmsp_daytime             37612 non-null  object \n",
      " 7   x_tmsp_h_sin               37612 non-null  float64\n",
      " 8   x_tmsp_h_cos               37612 non-null  float64\n",
      " 9   x_tmsp_wd_sin              37612 non-null  float64\n",
      " 10  x_tmsp_wd_cos              37612 non-null  float64\n",
      " 11  x_enc_country_Austria      37612 non-null  bool   \n",
      " 12  x_enc_country_Germany      37612 non-null  bool   \n",
      " 13  x_enc_country_Switzerland  37612 non-null  bool   \n",
      " 14  x_enc_psp_Goldcard         37612 non-null  bool   \n",
      " 15  x_enc_psp_Moneycard        37612 non-null  bool   \n",
      " 16  x_enc_psp_Simplecard       37612 non-null  bool   \n",
      " 17  x_enc_psp_UK_Card          37612 non-null  bool   \n",
      " 18  x_enc_card_Diners          37612 non-null  bool   \n",
      " 19  x_enc_card_Master          37612 non-null  bool   \n",
      " 20  x_enc_card_Visa            37612 non-null  bool   \n",
      "dtypes: bool(10), float64(4), int64(2), object(5)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_trx[x_].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6adc2-f46e-49e0-8e5c-e706142357fe",
   "metadata": {},
   "source": [
    "Je nach Modell gibt es 2 Features-Sets:<br>\n",
    "\n",
    "Für Modelle, die numerische Features benötigen: \n",
    "- 16 Features\n",
    "- davon 6 numerische Features, die skaliert werden müssen\n",
    "- und 10 Features vom Typ Boolean, die aus dem One Hot Encoding entstanden sind und als Integer encoded werden<br>\n",
    "\n",
    "Für Modelle, bei denen der Typ der Features egal ist:\n",
    "- 11 Features\n",
    "- davon 6 numerische Features\n",
    "- und 5 categorial Features vom Typ Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5577b15c-f507-4777-95ff-9412a035ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize features\n",
    "feat_object_native = list(df_trx[x_].select_dtypes(include=\"object\").columns) # original features of type object\n",
    "#feat_object_bool_enc = list(df_trx[x_].select_dtypes(include=\"bool\").columns) # encoded object features as bool\n",
    "feat_num = list(df_trx[x_].select_dtypes(include=\"number\").columns) # numerical features for scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dba4fc-54b8-4f6a-9362-955246c6426d",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16057397-cc6c-4ba5-a29f-ba6a722e10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_trx[x_], df_trx[y_], test_size=0.2, random_state=rs, shuffle=True)\n",
    "y_train= y_train.iloc[:, 0]\n",
    "y_test= y_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a48092-caac-4827-8951-3deba27a6f3e",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d1003b-2a87-4888-91fb-0f4b16844fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer for models requiring numerical, scaled input features\n",
    "coltransformer_4numerical = make_column_transformer(\n",
    "    (MinMaxScaler(), make_column_selector(dtype_include=\"number\")), \n",
    "    (OrdinalEncoder(), make_column_selector(dtype_include=\"bool\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480c6ff-fae8-40a2-9d71-154c461845f8",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76340a0-a00d-4b90-b751-5f7d0a13de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model with numerical input\n",
    "x_train_numerical = coltransformer_4numerical.fit_transform(x_train)\n",
    "x_test_numerical = coltransformer_4numerical.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464ba462-2a14-464c-90e1-9d9728cbe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model with raw input\n",
    "x_train_raw = x_train[feat_num + feat_object_native]\n",
    "x_test_raw = x_test[feat_num + feat_object_native]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507a335-d408-430e-82ee-251a3eecb53f",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "- Logistic regression: Scaling\n",
    "- Naive Bayes\n",
    "- KNN: Normalization\n",
    "- Decision Tree\n",
    "- SVM\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0062566-a494-483a-9198-13d6362a7bcc",
   "metadata": {},
   "source": [
    "## Test design\n",
    "Ziele:\n",
    "- erfolgreiche Transaktionen in Abhängigkeit vom PSP (und den anderen Umständen) erkennen\n",
    "- positiv = success\n",
    "\n",
    "Vergleich der Modelle:\n",
    "- Wir sind nicht nur an der Klassifikation an sich interessiert, sondern v.a. auch an der Wahrscheinlichkeit für einen Erfolg abhängig von der Wahrscheinlichkeit.\n",
    "- AUC ist eine Vergleichsmetrik, die unabhängig vom gewählten Threshold ist.\n",
    "\n",
    "Übergeordnete Metriken zur Bewertung der Performance:\n",
    "- Precision meiner Vorhersage: keine Falschpositiven, um mehrfache Transaktionsgebühren zu sparen\n",
    "- Recall/TPR/Sensitivity: möglichst viele erfolgreiche Transaktionen vorhersagen, um eine Auswahl an PSPs zu haben, um die Kosten minimieren zu können\n",
    "- F1-Score als harmonisches Mittel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b4dce-5d41-4aeb-ab9b-7002f0fd611b",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "2 Strategien kommen in Frage:\n",
    "- most_frequent: macht wenig Sinn, weil dann kein Erfolg vorhergesagt wird, so dass Precision nicht berechnet werden kann. Recall/Sensitity ist ebenfalls = 0\n",
    "- stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28f5b0aa-b910-49aa-8f56-2a72cf20673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-model\n",
      "with AUC: 0.51\n",
      "with precision: 0.21\n",
      "with recall: 0.22\n",
      "and F1-score: 0.21\n"
     ]
    }
   ],
   "source": [
    "# Training and prediction\n",
    "baseline_clf = DummyClassifier(strategy=\"stratified\", random_state=rs)\n",
    "baseline_clf.fit(x_train_raw, y_train)\n",
    "\n",
    "y_pred_baseline = baseline_clf.predict(x_test_raw)\n",
    "auc = roc_auc_score(y_test, y_pred_baseline)\n",
    "prec = precision_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "recall = recall_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "f1 = f1_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "\n",
    "print(f\"Baseline-model\")\n",
    "print(f\"with AUC: {auc:.2f}\")\n",
    "print(f\"with precision: {prec:.2f}\")\n",
    "print(f\"with recall: {recall:.2f}\")\n",
    "print(f\"and F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7fa4d-c415-4de9-a236-96e223866f10",
   "metadata": {},
   "source": [
    "## 1st basic model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "540e6553-e583-4730-81fd-72c768ef6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(experiment_name, run_name, training_info, clf, x_train, y_train, x_test, y_test):\n",
    "    # Create a new MLflow Experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Start an MLflow run\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        # Set a tag that we can use to remind ourselves what this run was for\n",
    "        mlflow.set_tag(\"Training Info\", training_info)\n",
    "        \n",
    "        # Training and prediction\n",
    "        model = clf\n",
    "        model.fit(x_train, y_train)\n",
    "        y_pred = model.predict(x_test)\n",
    "        \n",
    "        # Log the hyperparameters\n",
    "        mlflow.log_params(model.get_params())\n",
    " \n",
    "        # Log the metrics\n",
    "        mlflow.log_metrics({\"AUC\": roc_auc_score(y_test, y_pred), \n",
    "                           \"Precision\": precision_score(y_test, y_pred, zero_division=np.nan), \n",
    "                           \"Recall\": recall_score(y_test, y_pred, zero_division=np.nan), \n",
    "                           \"F1-score\": f1_score(y_test, y_pred, zero_division=np.nan)})\n",
    "        \n",
    "\n",
    "        \n",
    "        # Log feature importance as artifacts\n",
    "        feat_imp = (pd.DataFrame(list(zip(x_train.columns, model.feature_importances_)), \n",
    "                                 columns=[\"Feature\", \"Importance\"])\n",
    "                    .sort_values(\"Importance\", ascending=False)\n",
    "                    .set_index(\"Feature\"))\n",
    "        csv_path = \"/artifacts/feature_importance.csv\"\n",
    "        feat_imp.to_csv(csv_path, index=True)\n",
    "        mlflow.log_artifact(csv_path, \"feature_importance.csv\")\n",
    "    \n",
    "        # Log plot of feature importance\n",
    "        fig, ax = plt.subplots()\n",
    "        feat_imp.plot.barh(ax=ax)\n",
    "        plt.title(\"Feature importance\")\n",
    "        plt.xlabel(\"Importance\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        mlflow.log_figure(fig, \"feature_importance.png\")\n",
    "        #print(f\"Feature importance not available for {run_name}\")\n",
    "        \n",
    "        # Infer the model signature\n",
    "        #signature = infer_signature(x_train, y_train)\n",
    "        # Log the model\n",
    "        \"\"\"model_info = mlflow.sklearn.log_model(sk_model=model, \n",
    "                                              artifact_path=\"baseline_model\", \n",
    "                                              signature=signature, \n",
    "                                              input_example=x_train.head(5))\"\"\"\n",
    "                                            \n",
    "        run_id = run.info.run_id\n",
    "        return run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67cdfb47-16cb-427f-9e1e-9157f3c4d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all models\n",
    "# names\n",
    "first_step_clf_names = [\"Baseline model stratified\", \n",
    "                        \"Logistic Regression\", \n",
    "                        \"Naive Bayes\", \n",
    "                        \"KNN\", \n",
    "                        \"Decision Tree\", \n",
    "                        \"Linear SVM\", \n",
    "                        \"Random Forest\", \n",
    "                        \"Gradient Boosting\"]\n",
    "\n",
    "# configure parameters per model\n",
    "params_baseline = {\"strategy\": \"stratified\", \"random_state\": rs}\n",
    "params_lr = {\"penalty\": None, \"random_state\":rs}\n",
    "params_rs = {\"random_state\": rs}\n",
    "\n",
    "# sklearn models without parameters\n",
    "first_step_clf = [DummyClassifier(**params_baseline), \n",
    "                  LogisticRegression(**params_lr), \n",
    "                  CategoricalNB(), \n",
    "                  KNeighborsClassifier(), \n",
    "                  DecisionTreeClassifier(**params_rs), \n",
    "                  LinearSVC(**params_rs), \n",
    "                  RandomForestClassifier(**params_rs), \n",
    "                  GradientBoostingClassifier()]\n",
    "\n",
    "# feature mode for model\n",
    "first_step_feat_mode = [\"raw\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\", \n",
    "                        \"numeric\"]\n",
    "\n",
    "#first_step_zip = zip(first_step_clf_names, first_step_clf, first_step_params)\n",
    "first_step_zip = zip(first_step_clf_names, first_step_clf, first_step_feat_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff635359-71a1-4166-bf7e-83cb74929056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _MetadataRequester.get_metadata_routing of ColumnTransformer(transformers=[('minmaxscaler', MinMaxScaler(),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000001E51349B410>),\n",
       "                                ('ordinalencoder', OrdinalEncoder(),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x000001E513420860>)])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coltransformer_4numerical.get_metadata_routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a359a262-402e-40ea-8744-436668aa8e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/07 19:34:41 INFO mlflow.tracking.fluent: Experiment with name 'test' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, DecisionTreeClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_rs), x_train_numerical, y_train, x_test_numerical, y_test)\n",
      "Cell \u001b[1;32mIn[16], line 27\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(experiment_name, run_name, training_info, clf, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m\"\u001b[39m: roc_auc_score(y_test, y_pred), \n\u001b[0;32m     20\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan), \n\u001b[0;32m     21\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan), \n\u001b[0;32m     22\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Log feature importance as artifacts\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m feat_imp \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mcolumns, model\u001b[38;5;241m.\u001b[39mfeature_importances_)), \n\u001b[0;32m     28\u001b[0m                          columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     31\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/artifacts/feature_importance.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m feat_imp\u001b[38;5;241m.\u001b[39mto_csv(csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "run_model(\"test\", \"test\",  \"test\", DecisionTreeClassifier(**params_rs), x_train_numerical, y_train, x_test_numerical, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0902b09-59e7-4290-9ca8-e895a2b04162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and logging of model Baseline model stratified as classifier DummyClassifier(random_state=23, strategy='stratified') with feature mode raw\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DummyClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m x_train_numerical\n\u001b[0;32m     11\u001b[0m     x_test \u001b[38;5;241m=\u001b[39m x_test_numerical\n\u001b[1;32m---> 13\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_model(first_exp, \n\u001b[0;32m     14\u001b[0m                    dt_today \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m n,  \n\u001b[0;32m     15\u001b[0m                    n \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m first_info, \n\u001b[0;32m     16\u001b[0m                    c,\n\u001b[0;32m     17\u001b[0m                    x_train, y_train, \n\u001b[0;32m     18\u001b[0m                    x_test, y_test)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Run logged in MLflow with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------- \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[16], line 27\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(experiment_name, run_name, training_info, clf, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metrics({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m\"\u001b[39m: roc_auc_score(y_test, y_pred), \n\u001b[0;32m     20\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan), \n\u001b[0;32m     21\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan), \n\u001b[0;32m     22\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1_score(y_test, y_pred, zero_division\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)})\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Log feature importance as artifacts\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m feat_imp \u001b[38;5;241m=\u001b[39m (pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(x_train\u001b[38;5;241m.\u001b[39mcolumns, model\u001b[38;5;241m.\u001b[39mfeature_importances_)), \n\u001b[0;32m     28\u001b[0m                          columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     31\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/artifacts/feature_importance.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m feat_imp\u001b[38;5;241m.\u001b[39mto_csv(csv_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DummyClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "first_exp = \"PSP_1st_comparison\"\n",
    "first_info = \"Training for first comparison of models without hyperparameter tuning\"\n",
    "for n, c, fm in first_step_zip:\n",
    "    print(f\"Training and logging of model {n} as classifier {c} with feature mode {fm}\")\n",
    "    if fm == \"raw\":\n",
    "        x_train = x_train_raw\n",
    "        x_test = x_test_raw\n",
    "\n",
    "    else:\n",
    "        x_train = x_train_numerical\n",
    "        x_test = x_test_numerical\n",
    "\n",
    "    run_id = run_model(first_exp, \n",
    "                       dt_today + \"_\" + n,  \n",
    "                       n + \" - \" + first_info, \n",
    "                       c,\n",
    "                       x_train, y_train, \n",
    "                       x_test, y_test)\n",
    "    \n",
    "    print(f\"For {n}: Run logged in MLflow with {run_id}.\")\n",
    "    print(\"---------------------- \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14a64b-d6df-4f2e-aefe-0efc9ffabadc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
