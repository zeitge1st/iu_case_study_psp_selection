{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6323f327-c470-42a5-aecc-4b8b68b11973",
   "metadata": {},
   "source": [
    "Fallstudie:<br> \n",
    "**Erstellen eines Prognosemodells des Kreditkartenzahlungsverkehr für Online-Einkäufe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e1e74e-0d09-436a-8f92-14ee75df9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167a0ecb-5f75-47b8-b2dc-06c157506e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.option_context('mode.use_inf_as_na', True)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid',)\n",
    "color_pal = sns.color_palette(\"muted\")\n",
    "sns.set_palette(color_pal)\n",
    "sns.set_context(\"paper\")\n",
    "%matplotlib inline\n",
    "# plot dimensions\n",
    "plot_width = 12\n",
    "plot_height = 8\n",
    "palette_success ={0: color_pal[1], 1: color_pal[2]}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, f1_score, recall_score\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "271c4c5e-40b0-4def-bf92-6e67810db034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "rs = 23 # random state\n",
    "\n",
    "# MLflow\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# date of today as string\n",
    "dt_today = str(dt.date.today())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27845bea-2fef-4bc9-868f-89a29663c32b",
   "metadata": {},
   "source": [
    "# Data preparation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8276cade-ad1a-46e2-aa75-0eb7dcd3b3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trx = (pd.read_excel(\"../data/03_interim/df_trx_training.xlsx\", sheet_name=\"df_trx\")\n",
    "          .drop(columns=[\"Unnamed: 0\"])\n",
    "          .rename(columns={\"x_tmsp\":\"meta_tmsp\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f590679a-d589-481e-bcc4-64bfee6c6449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw x- and y-variables\n",
    "x_ = [x for x in list(df_trx.columns) if re.match(\"^x_\", x)!=None]\n",
    "y_ = [y for y in list(df_trx.columns) if re.match(\"^y_\", y)!=None]\n",
    "meta_ = [m for m in list(df_trx.columns) if m.find(\"meta_\")!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba8f6c0-7cc1-42a1-adb1-d787e66cde75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37612 entries, 0 to 37611\n",
      "Data columns (total 21 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   x_country                  37612 non-null  object \n",
      " 1   x_amount                   37612 non-null  int64  \n",
      " 2   x_psp                      37612 non-null  object \n",
      " 3   x_3d_secured               37612 non-null  int64  \n",
      " 4   x_card                     37612 non-null  object \n",
      " 5   x_tmsp_wd_str              37612 non-null  object \n",
      " 6   x_tmsp_daytime             37612 non-null  object \n",
      " 7   x_tmsp_h_sin               37612 non-null  float64\n",
      " 8   x_tmsp_h_cos               37612 non-null  float64\n",
      " 9   x_tmsp_wd_sin              37612 non-null  float64\n",
      " 10  x_tmsp_wd_cos              37612 non-null  float64\n",
      " 11  x_enc_country_Austria      37612 non-null  bool   \n",
      " 12  x_enc_country_Germany      37612 non-null  bool   \n",
      " 13  x_enc_country_Switzerland  37612 non-null  bool   \n",
      " 14  x_enc_psp_Goldcard         37612 non-null  bool   \n",
      " 15  x_enc_psp_Moneycard        37612 non-null  bool   \n",
      " 16  x_enc_psp_Simplecard       37612 non-null  bool   \n",
      " 17  x_enc_psp_UK_Card          37612 non-null  bool   \n",
      " 18  x_enc_card_Diners          37612 non-null  bool   \n",
      " 19  x_enc_card_Master          37612 non-null  bool   \n",
      " 20  x_enc_card_Visa            37612 non-null  bool   \n",
      "dtypes: bool(10), float64(4), int64(2), object(5)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_trx[x_].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f6adc2-f46e-49e0-8e5c-e706142357fe",
   "metadata": {},
   "source": [
    "Je nach Modell gibt es 2 Features-Sets:<br>\n",
    "\n",
    "Für Modelle, die numerische Features benötigen: \n",
    "- 16 Features\n",
    "- davon 6 numerische Features, die skaliert werden müssen\n",
    "- und 10 Features vom Typ Boolean, die aus dem One Hot Encoding entstanden sind und als Integer encoded werden<br>\n",
    "\n",
    "Für Modelle, bei denen der Typ der Features egal ist:\n",
    "- 11 Features\n",
    "- davon 6 numerische Features\n",
    "- und 5 categorial Features vom Typ Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5577b15c-f507-4777-95ff-9412a035ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize features\n",
    "feat_object_native = list(df_trx[x_].select_dtypes(include=\"object\").columns) # original features of type object\n",
    "#feat_object_bool_enc = list(df_trx[x_].select_dtypes(include=\"bool\").columns) # encoded object features as bool\n",
    "feat_num = list(df_trx[x_].select_dtypes(include=\"number\").columns) # numerical features for scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dba4fc-54b8-4f6a-9362-955246c6426d",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16057397-cc6c-4ba5-a29f-ba6a722e10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_trx[x_], df_trx[y_], test_size=0.2, random_state=rs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a48092-caac-4827-8951-3deba27a6f3e",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d1003b-2a87-4888-91fb-0f4b16844fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column transformer for models requiring numerical, scaled input features\n",
    "coltransformer_4numerical = make_column_transformer(\n",
    "    (MinMaxScaler(), make_column_selector(dtype_include=\"number\")), \n",
    "    (OrdinalEncoder(), make_column_selector(dtype_include=\"bool\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480c6ff-fae8-40a2-9d71-154c461845f8",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76340a0-a00d-4b90-b751-5f7d0a13de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model with numerical input\n",
    "x_train_numerical = coltransformer_4numerical.fit_transform(x_train)\n",
    "x_test_numerical = coltransformer_4numerical.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "464ba462-2a14-464c-90e1-9d9728cbe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model with raw input\n",
    "x_train_raw = x_train[feat_num + feat_object_native]\n",
    "x_test_raw = x_test[feat_num + feat_object_native]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507a335-d408-430e-82ee-251a3eecb53f",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "- Logistic regression: Scaling\n",
    "- Naive Bayes\n",
    "- KNN: Normalization\n",
    "- Decision Tree\n",
    "- SVM\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0062566-a494-483a-9198-13d6362a7bcc",
   "metadata": {},
   "source": [
    "## Test design\n",
    "Ziele:\n",
    "- erfolgreiche Transaktionen in Abhängigkeit vom PSP (und den anderen Umständen) erkennen\n",
    "- positiv = success\n",
    "\n",
    "Vergleich der Modelle:\n",
    "- Wir sind nicht nur an der Klassifikation an sich interessiert, sondern v.a. auch an der Wahrscheinlichkeit für einen Erfolg abhängig von der Wahrscheinlichkeit.\n",
    "- AUC ist eine Vergleichsmetrik, die unabhängig vom gewählten Threshold ist.\n",
    "\n",
    "Übergeordnete Metriken zur Bewertung der Performance:\n",
    "- Precision meiner Vorhersage: keine Falschpositiven, um mehrfache Transaktionsgebühren zu sparen\n",
    "- Recall/TPR/Sensitivity: möglichst viele erfolgreiche Transaktionen vorhersagen, um eine Auswahl an PSPs zu haben, um die Kosten minimieren zu können\n",
    "- F1-Score als harmonisches Mittel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b4dce-5d41-4aeb-ab9b-7002f0fd611b",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "2 Strategien kommen in Frage:\n",
    "- most_frequent: macht wenig Sinn, weil dann kein Erfolg vorhergesagt wird, so dass Precision nicht berechnet werden kann. Recall/Sensitity ist ebenfalls = 0\n",
    "- stratified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78461c30-6b20-4bea-a482-0af07eff4616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-model\n",
      "with AUC: 0.51\n",
      "with precision: 0.21\n",
      "with recall: 0.22\n",
      "and F1-score: 0.21\n"
     ]
    }
   ],
   "source": [
    "# Training and prediction\n",
    "baseline_clf = DummyClassifier(strategy=\"stratified\", random_state=rs)\n",
    "baseline_clf.fit(x_train_raw, y_train)\n",
    "\n",
    "y_pred_baseline = baseline_clf.predict(x_test_raw)\n",
    "auc = roc_auc_score(y_test, y_pred_baseline)\n",
    "prec = precision_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "recall = recall_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "f1 = f1_score(y_test, y_pred_baseline, zero_division=np.nan)\n",
    "\n",
    "print(f\"Baseline-model\")\n",
    "print(f\"with AUC: {auc:.2f}\")\n",
    "print(f\"with precision: {prec:.2f}\")\n",
    "print(f\"with recall: {recall:.2f}\")\n",
    "print(f\"and F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be15b26-86f6-4f58-85d1-4abf43a542b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/04 19:21:16 INFO mlflow.tracking.fluent: Experiment with name '2024-04-04_Baseline' does not exist. Creating a new experiment.\n",
      "2024/04/04 19:21:16 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tag(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Info\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline model using stratified strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Infer the model signature\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m signature \u001b[38;5;241m=\u001b[39m infer_signature(x_train_raw, baseline_clf\u001b[38;5;241m.\u001b[39mpredict(y_train))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Log the model\u001b[39;00m\n\u001b[0;32m     22\u001b[0m model_info \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mlog_model(\n\u001b[0;32m     23\u001b[0m     sk_model\u001b[38;5;241m=\u001b[39mbaseline_clf,\n\u001b[0;32m     24\u001b[0m     artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     registered_model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\models\\signature.py:218\u001b[0m, in \u001b[0;36minfer_signature\u001b[1;34m(model_input, model_output, params)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer_signature\u001b[39m(\n\u001b[0;32m    140\u001b[0m     model_input: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    141\u001b[0m     model_output: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlflowInferableDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m     params: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelSignature:\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Infer an MLflow model signature from the training data (input), model predictions (output)\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    and parameters (for inference).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m      ModelSignature\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m _infer_schema(model_input) \u001b[38;5;28;01mif\u001b[39;00m model_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m _infer_schema(model_output) \u001b[38;5;28;01mif\u001b[39;00m model_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     params \u001b[38;5;241m=\u001b[39m _infer_param_schema(params) \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:329\u001b[0m, in \u001b[0;36m_infer_schema\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# pandas.DataFrame\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[0;32m    326\u001b[0m     schema \u001b[38;5;241m=\u001b[39m Schema(\n\u001b[0;32m    327\u001b[0m         [\n\u001b[0;32m    328\u001b[0m             ColSpec(\n\u001b[1;32m--> 329\u001b[0m                 \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m_infer_pandas_column(data[col]),\n\u001b[0;32m    330\u001b[0m                 name\u001b[38;5;241m=\u001b[39mcol,\n\u001b[0;32m    331\u001b[0m                 required\u001b[38;5;241m=\u001b[39m_infer_required(data[col]),\n\u001b[0;32m    332\u001b[0m             )\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m         ]\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# numpy.ndarray\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:472\u001b[0m, in \u001b[0;36m_infer_pandas_column\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m col\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;66;03m# We convert pandas Series into list and infer the schema.\u001b[39;00m\n\u001b[0;32m    471\u001b[0m         \u001b[38;5;66;03m# The real schema for internal field should be the Array's dtype\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m         arr_type \u001b[38;5;241m=\u001b[39m _infer_colspec_type(col\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[0;32m    473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m arr_type\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    475\u001b[0m         \u001b[38;5;66;03m# For backwards compatibility, we fall back to string\u001b[39;00m\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;66;03m# if the provided array is of string type\u001b[39;00m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# This is for diviner test where df field is ('key2', 'key1', 'key0')\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:97\u001b[0m, in \u001b[0;36m_infer_colspec_type\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_infer_colspec_type\u001b[39m(data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[DataType, Array, Object]:\n\u001b[0;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    Infer an MLflow Colspec type from the dataset.\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m        Object\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m _infer_datatype(data)\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Currently only input that gives None is nested list whose items are all empty e.g. [[], []],\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# because flat empty list [] has special handlign logic in _infer_schema\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:120\u001b[0m, in \u001b[0;36m_infer_datatype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Object(properties\u001b[38;5;241m=\u001b[39mproperties)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _infer_array_datatype(data)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _infer_scalar_datatype(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:149\u001b[0m, in \u001b[0;36m_infer_array_datatype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_none_or_nan(item):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _infer_datatype(item)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Skip item with undetermined type\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:122\u001b[0m, in \u001b[0;36m_infer_datatype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mlist\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _infer_array_datatype(data)\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _infer_scalar_datatype(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\utils.py:187\u001b[0m, in \u001b[0;36m_infer_scalar_datatype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39minteger\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Order of is_double & is_float matters\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# as both of their python_types are float\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39mis_double(data):\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39mdouble\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39mis_float(data):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\schema.py:99\u001b[0m, in \u001b[0;36mDataType.is_double\u001b[1;34m(cls, value)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_double\u001b[39m(\u001b[38;5;28mcls\u001b[39m, value):\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(value) \u001b[38;5;129;01min\u001b[39;00m DataType\u001b[38;5;241m.\u001b[39mdouble\u001b[38;5;241m.\u001b[39mget_all_types()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\venv_iu_model_engineering\\Lib\\site-packages\\mlflow\\types\\schema.py:115\u001b[0m, in \u001b[0;36mDataType.get_all_types\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_types\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    114\u001b[0m     types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_numpy(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_pandas(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_python()]\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyspark\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         types\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_spark())\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m<frozen importlib.util>:100\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(name, package)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1262\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1525\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1499\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1598\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(f\"{dt_today}_Baseline\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log the hyperparameters\n",
    "    #mlflow.log_params(params)\n",
    "\n",
    "    # Log the metric\n",
    "    mlflow.log_metric(\"AUC\", auc)\n",
    "    mlflow.log_metric(\"Precision\", prec)\n",
    "    mlflow.log_metric(\"Recall\", recall)\n",
    "    mlflow.log_metric(\"F1\", f1)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Baseline model using stratified strategy\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(x_train_raw, baseline_clf.predict(y_train))\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=baseline_clf,\n",
    "        artifact_path=\"baseline_model\",\n",
    "        signature=signature,\n",
    "        input_example=x_train_raw,\n",
    "        registered_model_name=\"baseline_model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f208c3-f0d0-43b1-a782-796bfcd57cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
